{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel\n",
    "### 因為一開始設定灰階，所以只有一個channel，需要轉換資料格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(10000,28,28,1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[66].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入必要的函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 打造函數學習機 (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一層Conv2D：Filter用32個和3*3的篩選機制；第一層MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3), padding='same',input_shape = (28,28,1), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二層Conv2D：Filter用64個和3*3的篩選機制；第二層MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64,(3,3),padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三層Conv2D：Filter用128個和3*3的篩選機制；第三層MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128,(3,3), padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(66, activation='relu')) #神經元設定66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10 ,activation='softmax')) #神經元設定10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 127)         73279     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         146432    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 66)                76098     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                670       \n",
      "=================================================================\n",
      "Total params: 319,717\n",
      "Trainable params: 319,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer = SGD(lr=0.088), metrics=['accuracy']) #設定學習率為0.088"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch_size為64, 訓練次數為16次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/16\n",
      "60000/60000 [==============================] - 125s 2ms/sample - loss: 0.0889 - accuracy: 0.3684\n",
      "Epoch 2/16\n",
      "60000/60000 [==============================] - 124s 2ms/sample - loss: 0.0599 - accuracy: 0.5593\n",
      "Epoch 3/16\n",
      "60000/60000 [==============================] - 124s 2ms/sample - loss: 0.0382 - accuracy: 0.7196\n",
      "Epoch 4/16\n",
      "60000/60000 [==============================] - 125s 2ms/sample - loss: 0.0327 - accuracy: 0.7647\n",
      "Epoch 5/16\n",
      "60000/60000 [==============================] - 135s 2ms/sample - loss: 0.0296 - accuracy: 0.7908\n",
      "Epoch 6/16\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.0275 - accuracy: 0.8074\n",
      "Epoch 7/16\n",
      "60000/60000 [==============================] - 137s 2ms/sample - loss: 0.0259 - accuracy: 0.8195\n",
      "Epoch 8/16\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.0245 - accuracy: 0.8302\n",
      "Epoch 9/16\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.0232 - accuracy: 0.8398\n",
      "Epoch 10/16\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 0.0223 - accuracy: 0.8449\n",
      "Epoch 11/16\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 0.0214 - accuracy: 0.8515\n",
      "Epoch 12/16\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0207 - accuracy: 0.8565\n",
      "Epoch 13/16\n",
      "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0200 - accuracy: 0.8616\n",
      "Epoch 14/16\n",
      "60000/60000 [==============================] - 96s 2ms/sample - loss: 0.0195 - accuracy: 0.8652\n",
      "Epoch 15/16\n",
      "60000/60000 [==============================] - 96s 2ms/sample - loss: 0.0190 - accuracy: 0.8686\n",
      "Epoch 16/16\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.0185 - accuracy: 0.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cbb7ca9088>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_predict(n):\n",
    "    print(\"CNN的預測是：\", class_names[result[n]])\n",
    "    X = x_test[n].reshape(28, 28)\n",
    "    plt.imshow(X, cmap = \"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN的預測是： Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNN_predict(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 418us/sample - loss: 0.0200 - accuracy: 0.8625\n",
      "測試資料的正確率是 0.8625\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test)\n",
    "loss, acc = score\n",
    "print('測試資料的正確率是', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把Model存起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
