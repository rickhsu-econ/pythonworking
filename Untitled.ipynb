{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, IntSlider, FloatSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Lambda, concatenate\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載並整理MNIST資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train0), (X_test, y_test0) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / X_train.max()\n",
    "X_test = X_test / X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_1 = Dense(128, activation='sigmoid')\n",
    "enc_2 = Dense(16, activation='sigmoid')\n",
    "\n",
    "# Define latent repre. of x\n",
    "z = enc_2(enc_1(x))\n",
    "\n",
    "dec_2 = Dense(128, activation='sigmoid')\n",
    "dec_1 = Dense(784, activation='sigmoid')\n",
    "\n",
    "x_hat = dec_1(dec_2(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784)               101136    \n",
      "=================================================================\n",
      "Total params: 205,856\n",
      "Trainable params: 205,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_mnist = Model(x, x_hat)\n",
    "autoencoder_mnist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_mnist.compile(loss='mse',\n",
    "                    optimizer=Adam(5e-3),\n",
    "                    metrics=['mae']\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0646 - mae: 0.1469 - val_loss: 0.0551 - val_mae: 0.1298\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0460 - mae: 0.1150 - val_loss: 0.0395 - val_mae: 0.1021\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0375 - mae: 0.0969 - val_loss: 0.0342 - val_mae: 0.0908\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0314 - mae: 0.0857 - val_loss: 0.0284 - val_mae: 0.0795\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0272 - mae: 0.0768 - val_loss: 0.0255 - val_mae: 0.0725\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0247 - mae: 0.0709 - val_loss: 0.0234 - val_mae: 0.0680\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0230 - mae: 0.0670 - val_loss: 0.0218 - val_mae: 0.0645\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0217 - mae: 0.0637 - val_loss: 0.0207 - val_mae: 0.0611\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0207 - mae: 0.0612 - val_loss: 0.0198 - val_mae: 0.0598\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0199 - mae: 0.0591 - val_loss: 0.0189 - val_mae: 0.0574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b6b6a2d6c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_mnist.fit(X_train, X_train, \n",
    "                batch_size=256, \n",
    "                epochs=10, ##訓練10次\n",
    "                validation_data=(X_test, X_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructed_img(idx):\n",
    "    # Prepare image to be reconstructed\n",
    "    X = X_train[idx:idx+1]\n",
    "    y = y_train0[idx]\n",
    "    X_hat = autoencoder.predict(X)\n",
    "\n",
    "    # Reshape for plotting  \n",
    "    X = X.reshape(28, 28)\n",
    "    X_hat = X_hat.reshape(28, 28)\n",
    "    rec_error = np.abs(X-X_hat)\n",
    "\n",
    "    # Prepare a canvas for plotting\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    ax1 = plt.subplot2grid((2,3),(0,0))\n",
    "    ax2 = plt.subplot2grid((2,3),(0,1))\n",
    "    ax3 = plt.subplot2grid((2,3),(0,2))\n",
    "    ax4 = plt.subplot2grid((2,3),(1,0), colspan=3)\n",
    "\n",
    "    # Plot raw image\n",
    "    ax1.imshow(X, 'Greys')\n",
    "    ax1.set_title(f'Number: {y}')\n",
    "\n",
    "    # Plot reconstructed image\n",
    "    ax2.imshow(X_hat, 'Greys')\n",
    "    ax2.set_title('Reconstructed Image')\n",
    "\n",
    "    # Plot reconstruction error\n",
    "    ax3.imshow(rec_error, 'Greys')\n",
    "    ax3.set_title('Reconstructed Error')\n",
    "    ax4.hist(rec_error.flatten(), bins=20, rwidth=0.5)\n",
    "    ax4.set_title('Histogram of Reconstructed Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder&Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 102,544\n",
      "Trainable params: 102,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Encoder = Model(x, z)\n",
    "Encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer dense_8 is incompatible with the layer: expected axis -1 of input shape to have value 16 but received input with shape [None, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-47216dc8c70a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mz_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mDecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[1;32m--> 737\u001b[1;33m                                               self.name)\n\u001b[0m\u001b[0;32m    738\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[0;32m    739\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[1;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;34m' of input shape to have value '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;31m# Check shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer dense_8 is incompatible with the layer: expected axis -1 of input shape to have value 16 but received input with shape [None, 2]"
     ]
    }
   ],
   "source": [
    "z_input = Input(shape=(2,))\n",
    "Decoder = Model(z_input, dec_1(dec_2(z_input)))\n",
    "\n",
    "Decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
